{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a617f86",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e120aebf",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "from tqdm.auto import tqdm, trange\n",
    "import control\n",
    "import notebook_setup\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from commonml.helpers.logs import get_tensorboard_scalar_frame\n",
    "\n",
    "from systems.base import SystemEnv\n",
    "from systems.plotting import (\n",
    "    plot_env_response,\n",
    "    multiple_response_plots\n",
    ")\n",
    "from rl import learn_rl, transform_rl_policy, evaluate_rl\n",
    "from xform import get_transforms\n",
    "from systems.simple import SimpleEnv\n",
    "from systems.springmass import SpringMassEnv\n",
    "from systems.pendulum import PendulumEnv\n",
    "from systems.cartpole import CartpoleEnv\n",
    "from systems.lunarlander import LanderEnv\n",
    "from mpcontrol import evaluate_mpc, learn_mpc, MPCAgent\n",
    "from lqcontrol import evaluate_lqr, learn_lqr, LQRAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89fd03",
   "metadata": {},
   "source": [
    "# Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59acb7",
   "metadata": {},
   "source": [
    "# Policy transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39868f30",
   "metadata": {},
   "source": [
    "## System specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217a3695",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_kwargs = dict(a=-0.1, b=1)\n",
    "learn_kwargs = dict(steps=200_000, seed=0, learning_rate=5e-3,\n",
    "                    n_steps=4000, batch_size=200, n_epochs=10,\n",
    "                    gamma=0.)\n",
    "q, r = np.asarray([[1]]), np.asarray([[0.00001]])\n",
    "xformA = np.asarray([[0.5]])\n",
    "xformB = np.asarray([[-0.5]])\n",
    "x0 = np.asarray([-2.5])\n",
    "make_env = lambda: SimpleEnv(**sys_kwargs, q=q, seed=0)\n",
    "def make_xform_env():\n",
    "    env = make_env()\n",
    "    env.system.A = xformA @ env.system.A\n",
    "    env.system.B = xformB @ env.system.B\n",
    "    return env\n",
    "sys = create_simple(**sys_kwargs, name='simple')\n",
    "env = make_env()\n",
    "\n",
    "# sys_kwargs = dict(k=4, m=0.2, df=0.01)\n",
    "# learn_kwargs = dict(steps=100_000, seed=0, learning_rate=2e-3,\n",
    "#                     n_steps=2048, batch_size=64, n_epochs=10,\n",
    "#                     gamma=0.)\n",
    "# q, r = np.asarray([[1,0], [0,1]]), np.asarray([[0.00001]])\n",
    "# angA, angB = np.pi/4, np.pi\n",
    "# scalarA, scalarB = 0.8, 0.5\n",
    "# xformA = np.asarray([[np.cos(angA), -np.sin(angA)],\n",
    "#                     [np.sin(angA), np.cos(angA)]]).T \\\n",
    "#         @ (np.eye(2) * scalarA)\n",
    "# xformB = np.asarray([[np.cos(angB), -np.sin(angB)],\n",
    "#                     [np.sin(angB), np.cos(angB)]]).T \\\n",
    "#         @ (np.eye(2) * scalarB)\n",
    "# x0 = np.asarray([-0.5, 0])\n",
    "# make_env = lambda: SpringMassEnv(**sys_kwargs, q=q, seed=0)\n",
    "# def make_xform_env():\n",
    "#     env = make_env()\n",
    "#     env.system.A = xformA @ env.system.A\n",
    "#     env.system.B = xformB @ env.system.B\n",
    "#     return env\n",
    "# env = make_env()\n",
    "# sys = create_spring(**sys_kwargs)\n",
    "\n",
    "# sys_kwargs = dict(m=0.1, l=1, g=10., df=0.02)\n",
    "# learn_kwargs = dict(steps=200_000, seed=0, learning_rate=1e-3,\n",
    "#                     n_steps=2048, batch_size=128, n_epochs=10,\n",
    "#                     gamma=0.99)\n",
    "# q, r = np.asarray([[10,0], [0,1e-1]]), np.asarray([[0.00001]])\n",
    "# angA, angB = np.pi/4, np.pi\n",
    "# scalarA, scalarB = 0.8, 0.5\n",
    "# xformA = np.asarray([[np.cos(angA), -np.sin(angA)],\n",
    "#                     [np.sin(angA), np.cos(angA)]]).T \\\n",
    "#         @ (np.eye(2) * scalarA)\n",
    "# xformB = np.asarray([[np.cos(angB), -np.sin(angB)],\n",
    "#                     [np.sin(angB), np.cos(angB)]]).T \\\n",
    "#         @ (np.eye(2) * scalarB)\n",
    "# x0 = np.asarray([-0.5, 0])\n",
    "# make_env = lambda: PendulumEnv(**sys_kwargs, q=q, seed=0)\n",
    "# def make_xform_env():\n",
    "#     env = PendulumEnv(**sys_kwargs, q=q, seed=0,\n",
    "#                       xformA=xformA, xformB=xformB)\n",
    "#     return env\n",
    "# env = make_env()\n",
    "# sys = create_pendulum(**sys_kwargs)\n",
    "\n",
    "# sys_kwargs = dict(mc=0.5, mp=0.1, l=1, g=10, df=0.01)\n",
    "# learn_kwargs = dict(steps=400_000, seed=0, learning_rate=2e-3,\n",
    "#                     n_steps=2048, batch_size=64, n_epochs=10,\n",
    "#                     gamma=0.99)\n",
    "# q = np.asarray([[1,0,0,0], [0,0.1,0,0],[0,0,1e-5,0],[0,0,0,1e-1]])\n",
    "# r = np.asarray([[0.00001]])\n",
    "# xformA = np.diagflat(np.random.RandomState(seed=0).randn(4))\n",
    "# xformB = np.diagflat(np.random.RandomState(seed=1).randn(4))\n",
    "# x0 = np.asarray([-np.pi/45, 0, 0, 0])\n",
    "# make_env = lambda: CartpoleEnv(**sys_kwargs, q=q, seed=0)\n",
    "# def make_xform_env():\n",
    "#     env = CartpoleEnv(**sys_kwargs, q=q, seed=0,\n",
    "#                       xformA=xformA, xformB=xformB)\n",
    "#     return env\n",
    "# env = make_env()\n",
    "# sys = create_cartpole(**sys_kwargs)\n",
    "\n",
    "# sys_kwargs = dict(vp=vp, sp=sp)\n",
    "# learn_kwargs = dict(steps=200_000, seed=0, learning_rate=2e-4, n_steps=2000,\n",
    "#                    gamma=0.8)\n",
    "# q = np.diagflat([1,1,1,0.1,0.1,0.1,1,1,1,0.1,0.1,0.1])\n",
    "# r = np.eye(4) * 1e-4\n",
    "# xformA = np.random.RandomState(seed=0).randn(12,12)\n",
    "# xformB = np.diagflat(np.random.RandomState(seed=1).randn(4))\n",
    "# x0 = np.zeros(12, dtype=np.float32)\n",
    "# make_env = lambda: MultirotorEnv(**sys_kwargs, seed=0)\n",
    "# def make_xform_env():\n",
    "#     env = MultirotorEnv(**sys_kwargs, q=q, seed=0,\n",
    "#                       xformA=xformA, xformB=xformB)\n",
    "#     return env\n",
    "# env = make_env()\n",
    "# sys = create_multirotor(**sys_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cd45d4",
   "metadata": {},
   "source": [
    "## Classical Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec38fa63",
   "metadata": {},
   "source": [
    "### Evaluation w/ LQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23abc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = make_env()\n",
    "env_ = make_xform_env()\n",
    "if not isinstance(env.system, control.LinearIOSystem):\n",
    "    warnings.warn(('Must be a linear system in StateSpace from. '\n",
    "                   'Use `control.linearize()` to convert.'))\n",
    "    sys = env.system.linearize(\n",
    "            np.zeros(env.system.nstates), np.zeros(env.system.ninputs))\n",
    "    sys_xform = env_.system.linearize(\n",
    "            np.zeros(env_.system.nstates), np.zeros(env_.system.ninputs))\n",
    "else:\n",
    "    sys = env.system\n",
    "    sys_xform = env_.system\n",
    "\n",
    "# Linear transformation with\n",
    "k_og, *_ = control.lqr(sys, q, r)\n",
    "sys_opt = sys.feedback(k_og)\n",
    "sys_opt.name = 'sys_opt'\n",
    "\n",
    "# transformed system but with old control law\n",
    "sys_xform_old = sys_xform.feedback(k_og)\n",
    "sys_xform_old.name = 'sys_xform_old'\n",
    "\n",
    "# Optimizing on modified system\n",
    "k, *_ = control.lqr(sys_xform, q, r)\n",
    "sys_xform_opt = sys_xform.feedback(k)\n",
    "sys_xform_opt.name = 'sys_xform_opt'\n",
    "\n",
    "# Optimizing using transformed law\n",
    "feedback = policy_transform(sys, xformA, xformB, k_og)\n",
    "sys_xform_opt2 = sys_xform.feedback(feedback)\n",
    "sys_xform_opt2.name = 'sys_xform_opt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(evaluate_lqr(k_og, make_env()))\n",
    "print(evaluate_lqr(k_og, make_xform_env()))\n",
    "print(evaluate_lqr(k, make_xform_env()))\n",
    "print(evaluate_lqr(feedback, make_xform_env()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ff5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_response_plots([\n",
    "    'old policy on old system',\n",
    "    lambda: plot_env_response(make_env(), x0, k_og),\n",
    "    'old policy on new system',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, k_og),\n",
    "    'Optimal LQR on new system',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, k),\n",
    "    'old policy transformation on new system',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, feedback)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e17cd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Evaluation w/ MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02760c0a",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = make_env()\n",
    "env_ = make_xform_env()\n",
    "if not isinstance(env.system, control.LinearIOSystem):\n",
    "    warnings.warn(('Must be a linear system in StateSpace from. '\n",
    "                   'Use `control.linearize()` to convert.'))\n",
    "    sys = env.system.linearize(\n",
    "            np.zeros(env.system.nstates), np.zeros(env.system.ninputs))\n",
    "    sys_xform = env_.system.linearize(\n",
    "            np.zeros(env_.system.nstates), np.zeros(env_.system.ninputs))\n",
    "else:\n",
    "    sys = env.system\n",
    "    sys_xform = env_.system\n",
    "state_xform, action_xform = policy_transform(sys, xformA, xformB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dcfde7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sys_xform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598c613",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(evaluate_mpc(make_env(), horizon=5, model_env=make_env()))\n",
    "print(evaluate_mpc(make_xform_env(), horizon=10, model_env=make_env()))\n",
    "print(evaluate_mpc(make_xform_env(), horizon=10, model_env=make_xform_env()))\n",
    "print(evaluate_mpc(make_xform_env(), horizon=10, model_env=make_env(), state_xform=state_xform, action_xform=action_xform))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db65e671",
   "metadata": {},
   "source": [
    "## Data-driven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a55a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment config\n",
    "\n",
    "# Whether the knowledge of the source system is known,\n",
    "# or approximated from sampled experiences\n",
    "data_driven_source = True\n",
    "# Whether to assume that the system transformations are known\n",
    "# and not approximate\n",
    "accurate_xfer = False\n",
    "# The factor by which action bounds are relaxed to fully allow the\n",
    "# transformed policy to interact with environment\n",
    "constrained_actions = None # True by default, not implemented yet\n",
    "buffer_episodes=5\n",
    "name = env.__class__.__name__\n",
    "if data_driven_source and not accurate_xfer:\n",
    "    name += 'StochasticAll'\n",
    "elif data_driven_source:\n",
    "    name += 'StochasticSource'\n",
    "elif not accurate_xfer:\n",
    "    name += 'StochasticXfer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309975d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train rl policy on original environment\n",
    "agent = learn_rl(make_env(), tensorboard_log=name+'/Source',\n",
    "                 **learn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0056902",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_env_response(make_env(), x0, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef354ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env()\n",
    "env_ = make_xform_env()\n",
    "state_xform, action_xform, info = get_transforms(agent, env, env_,\n",
    "                                                 buffer_episodes, 'episodes',\n",
    "                                                 info.F_A, info.F_B, data_driven_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b3e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tine source policy on target environment\n",
    "agent_new = learn_rl(make_xform_env(),\n",
    "                     reuse_parameters_of=agent,\n",
    "                     tensorboard_log=name+'/Tuned', **learn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e616e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# append a transformation to source policy\n",
    "agent_xform = transform_rl_policy(agent, state_xform, action_xform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1ffcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fine-tine the transformed policy, except xforms\n",
    "agent_xform_tuned = learn_rl(\n",
    "    make_xform_env(),\n",
    "    reuse_parameters_of=agent_xform,\n",
    "    learnable_transformation=False,\n",
    "    tensorboard_log=name+'/XformedTuned', **learn_kwargs\n",
    ")\n",
    "print('state_xform', agent_xform_tuned.policy.state_xform)\n",
    "print('action_xform', agent_xform_tuned.policy.action_xform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc95eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tine the transformed policy, including xforms\n",
    "agent_xform_tuned_all = learn_rl(\n",
    "    make_xform_env(),\n",
    "    reuse_parameters_of=agent_xform,\n",
    "    learnable_transformation=True,\n",
    "    tensorboard_log=name+'/XformedTunedAll', **learn_kwargs\n",
    ")\n",
    "print('state_xform', agent_xform_tuned_all.policy.state_xform.data)\n",
    "print('action_xform', agent_xform_tuned_all.policy.action_xform.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cbb528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Source policy on source task')\n",
    "print(evaluate_rl(agent, make_env(), n_eval_episodes=10))\n",
    "print('Reusing source policy')\n",
    "print(evaluate_rl(agent, make_xform_env(), n_eval_episodes=10))\n",
    "print('Tuning source policy')\n",
    "print(evaluate_rl(agent_new, make_xform_env(), n_eval_episodes=10))\n",
    "print('Transforming source policy')\n",
    "print(evaluate_rl(agent_xform, make_xform_env(), n_eval_episodes=10))\n",
    "print('Tuning transformed policy, except for transformations')\n",
    "print(evaluate_rl(agent_xform_tuned, make_xform_env(), n_eval_episodes=10))\n",
    "print('Tuning transformed policy, including transformations')\n",
    "print(evaluate_rl(agent_xform_tuned_all, make_xform_env(), n_eval_episodes=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e603d",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816103ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multiple_response_plots([\n",
    "#     r'$\\pi_s$ on $P_s$ ',\n",
    "#     lambda: plot_env_response(make_env(), x0, agent),\n",
    "    r'$\\pi_s$ on $P_t$ ',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, agent),\n",
    "    r'$\\pi_s^*$ on $P_t$ ',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, agent_new, legend=False),\n",
    "    r'$\\pi_t$ on $P_t$ ',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, agent_xform, legend=False),\n",
    "    r'$\\pi_t^-$ on $P_t$ ',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, agent_xform_tuned, legend=False),\n",
    "    r'$\\pi_t^*$ on $P_t$ ',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, agent_xform_tuned_all, legend=False)\n",
    "], figsize=(6,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a075f29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remember to specify up-to-date directory\n",
    "# name = env.__class__.__name__\n",
    "df = get_tensorboard_scalar_frame('tensorboard/%s/Source_1' % name)\n",
    "dft = get_tensorboard_scalar_frame('tensorboard/%s/Tuned_1' % name)\n",
    "dfxt = get_tensorboard_scalar_frame('tensorboard/%s/XformedTuned_1' % name)\n",
    "dfxta = get_tensorboard_scalar_frame('tensorboard/%s/XformedTunedAll_1' % name)\n",
    "\n",
    "%matplotlib inline\n",
    "last_tstep = df.index[-1]\n",
    "plt.figure(figsize=(6,2))\n",
    "for i, (frame, label) in enumerate([\n",
    "    (df, '$\\pi_s$ on $P_s$'),\n",
    "    (dft, '$\\pi_s^*$ on $P_t$'),\n",
    "    (dfxt, '$\\pi_t^-$ on $P_t$'),\n",
    "    (dfxta, '$\\pi_t^+$ on $P_t$')\n",
    "]):\n",
    "    if i > 0:\n",
    "        frame.index = frame.index + last_tstep\n",
    "    plt.plot(frame['rollout', 'ep_rew_mean'], label=label)\n",
    "if name.startswith('Simp'):\n",
    "    plt.legend()\n",
    "plt.ylabel('Mean episodic reward')\n",
    "plt.xlabel('Learning time steps')\n",
    "plt.setp(plt.xticks()[1], rotation=15)\n",
    "plt.grid(True, 'both')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d10df0e4cfad4a81e3051546436717ccc1eaea03864256b4a2f98229345d5e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
